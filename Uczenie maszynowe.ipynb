{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e33f37",
   "metadata": {},
   "source": [
    "### Exploring the impact of clustering on the quality of SMOTE preprocessing. Comparative analysis\n",
    "##### Maksym Malicki, Jacek Glapiński\n",
    "###### Wrocław University of Technology\n",
    "In this notebook we present a comparative analysis of the impact of clustering using various methods on the quality of SMOTE preprocessing.\n",
    "\n",
    "#### load_dataset()\n",
    "This method allows us to load datasets listed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca3bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('@'):\n",
    "                continue\n",
    "            line_data = line.strip().split(',')\n",
    "            sample_class = line_data[-1].strip().lower().replace(\" \", \"\")\n",
    "            label = 1 if sample_class == 'positive' else 0\n",
    "            converted_data = []\n",
    "            for x in line_data[:-1]:\n",
    "                try:\n",
    "                    converted_data.append(float(x))\n",
    "                except ValueError:\n",
    "                    converted_data.append(ord(x))\n",
    "            data.append(converted_data)\n",
    "            labels.append(label)\n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43e67b",
   "metadata": {},
   "source": [
    "#### Clustering with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba7497e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift\n",
    "\n",
    "def imbalance_ratio(labels):\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    minority_class_count = np.min(label_counts)\n",
    "    majority_class_count = np.max(label_counts)\n",
    "    imbalance_ratio = minority_class_count / majority_class_count\n",
    "\n",
    "    return imbalance_ratio\n",
    "\n",
    "def oversample_clustered_data(X, y, cluster_labeled_data):\n",
    "    imbalance_ratios = []\n",
    "    cluster_labels = np.unique(cluster_labeled_data)\n",
    "    for cluster in cluster_labels:\n",
    "        cluster_samples_indices = np.where(cluster_labeled_data == cluster)[0]\n",
    "        samples_labels_in_cluster = y[cluster_samples_indices]\n",
    "        imbalance_ratios.append((cluster, imbalance_ratio(samples_labels_in_cluster)))\n",
    "    sorted_clusters = sorted(imbalance_ratios, key=lambda x: x[1])\n",
    "    cluster_to_oversample = sorted_clusters[-1][0]\n",
    "    cluster_indices_to_oversample = np.where(cluster_labels == cluster_to_oversample)[0]\n",
    "    smote = SMOTE()\n",
    "    print(y[cluster_indices_to_oversample], cluster_indices_to_oversample)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X[cluster_indices_to_oversample], y[cluster_indices_to_oversample])\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def KMeans_SMOTE(X, y, num_clusters):\n",
    "    kmeans_labels = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit_predict(X)\n",
    "    return oversample_clustered_data(X, y, kmeans_labels)\n",
    "\n",
    "\n",
    "def MeanShift_SMOTE(X, y):\n",
    "    mean_shift_labels = MeanShift().fit_predict(X)\n",
    "    return oversample_clustered_data(X, y, mean_shift_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3846ea",
   "metadata": {},
   "source": [
    "#### Experiment for single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "915d9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, BorderlineSMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "def experiment(X, y):\n",
    "    preprocessings = {\n",
    "        \"KMeansSMOTE\": True,\n",
    "        \"MeansShiftSMOTE\": True,\n",
    "        \"SMOTE\": SMOTE(),\n",
    "        \"ROS\": RandomOverSampler(),\n",
    "        \"BorderlineSMOTE\": BorderlineSMOTE(),\n",
    "    }\n",
    "    classifier = svm.SVC(),\n",
    "    classifier = classifier[0]\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1234)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    specifity_scores = []\n",
    "    for key in preprocessings:\n",
    "        for train_index, test_index in rskf.split(X,y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            if key == \"KMeansSMOTE\":\n",
    "                X_train_oversampled, y_train_oversampled = KMeans_SMOTE(X_train, y_train, 2)\n",
    "            elif key == \"MeansShiftSMOTE\":\n",
    "                X_train_oversampled, y_train_oversampled = MeanShift_SMOTE(X_train, y_train)\n",
    "            else:\n",
    "                X_train_oversampled, y_train_oversampled = preprocessings[key].fit_resample(X_train, y_train)\n",
    "            classifier.fit(X_train_oversampled, y_train_oversampled)\n",
    "            predict = classifier.predict(X_test)\n",
    "            precision_scores.append(precision_score(y_test, predict))\n",
    "            recall_scores.append(recall_score(y_test, predict))\n",
    "            specifity_scores.append(specificity_score(y_test, predict))\n",
    "        mean_precision_score = np.mean(precision_scores)\n",
    "        std_precision_score = np.std(precision_scores)\n",
    "        mean_recall_scores = np.mean(recall_scores)\n",
    "        std_recall_scores = np.std(recall_scores)\n",
    "        mean_specifity_scores = np.mean(specifity_scores)\n",
    "        std_specifity_scores = np.std(specifity_scores)\n",
    "        print(f\"Precission score {key}: %.3f (%.3f)\" % (mean_precision_score, std_precision_score))\n",
    "        print(f\"Specifity score {key}: %.3f (%.3f)\" % (mean_specifity_scores, std_specifity_scores))\n",
    "        print(f\"Recall score {key}: %.3f (%.3f)\" % (mean_recall_scores, std_recall_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268e808",
   "metadata": {},
   "source": [
    "#### Running experiments on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b9c68f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in directory: mild-imbalance\n",
      "['vehicle1.dat', 'vehicle0.dat', 'vehicle2.dat', 'vehicle3.dat', 'yeast3.dat', 'page-blocks0.dat', 'yeast1.dat', 'pima.dat', 'segment0.dat', 'wisconsin.dat']\n",
      "File: mild-imbalance/vehicle1.dat\n",
      "[0] [1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_dataset(file_path)\n\u001b[0;32m---> 13\u001b[0m experiment(X, y)\n",
      "Cell \u001b[0;32mIn[60], line 26\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKMeansSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     X_train_oversampled, y_train_oversampled \u001b[38;5;241m=\u001b[39m KMeans_SMOTE(X_train, y_train, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeansShiftSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m     X_train_oversampled, y_train_oversampled \u001b[38;5;241m=\u001b[39m MeanShift_SMOTE(X_train, y_train)\n",
      "Cell \u001b[0;32mIn[59], line 28\u001b[0m, in \u001b[0;36mKMeans_SMOTE\u001b[0;34m(X, y, num_clusters)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mKMeans_SMOTE\u001b[39m(X, y, num_clusters):\n\u001b[1;32m     27\u001b[0m     kmeans_labels \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_predict(X)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m oversample_clustered_data(X, y, kmeans_labels)\n",
      "Cell \u001b[0;32mIn[59], line 23\u001b[0m, in \u001b[0;36moversample_clustered_data\u001b[0;34m(X, y, cluster_labeled_data)\u001b[0m\n\u001b[1;32m     21\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(y[cluster_indices_to_oversample], cluster_indices_to_oversample)\n\u001b[0;32m---> 23\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X[cluster_indices_to_oversample], y[cluster_indices_to_oversample])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_resampled, y_resampled\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:84\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m     82\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     88\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m     90\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     92\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py:514\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[0;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLING_KIND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m     )\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to have more than 1 class. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m class instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampling_strategy\n",
      "\u001b[0;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directories = ['mild-imbalance', 'high-imbalance']\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in directory: {directory}\")\n",
    "    files = os.listdir(directory)\n",
    "    print(files)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        print(f\"File: {file_path}\")\n",
    "        X, y = load_dataset(file_path)\n",
    "        experiment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c0605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
